'use strict';

var core = require('@metorial/core');
var mcpSession = require('@metorial/mcp-session');
var openai = require('@metorial/openai');
var anthropic = require('@metorial/anthropic');
var deepseek = require('@metorial/deepseek');
var google = require('@metorial/google');
var mistral = require('@metorial/mistral');
var xai = require('@metorial/xai');
var togetherai = require('@metorial/togetherai');

// src/metorial.ts
var runWithOpenAI = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    ...openaiOptions
  } = config;
  return withProviderSession(
    openai.metorialOpenAI.chatCompletions,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      let tools = requestedTools ? session.tools.filter((t) => requestedTools.includes(t.name)) : session.tools;
      let messages = [
        { role: "user", content: message }
      ];
      for (let step = 0; step < maxSteps; step++) {
        let response = await client.chat.completions.create({
          model,
          messages,
          tools,
          ...openaiOptions
        });
        let choice = response.choices[0];
        if (!choice.message.tool_calls) {
          return {
            text: choice.message.content || "",
            steps: step + 1
          };
        }
        let toolResponses = await session.callTools(choice.message.tool_calls);
        messages.push(
          { role: "assistant", tool_calls: choice.message.tool_calls },
          ...toolResponses
        );
      }
      throw new Error(`Max steps (${maxSteps}) reached without final response`);
    }
  );
};
var runWithAnthropic = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    max_tokens = 4096,
    ...anthropicOptions
  } = config;
  return withProviderSession(
    anthropic.metorialAnthropic,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      let tools = requestedTools ? session.tools.filter((t) => requestedTools.includes(t.name)) : session.tools;
      let messages = [
        { role: "user", content: message }
      ];
      let uniqueTools = Array.from(new Map(tools.map((t) => [t.name, t])).values());
      for (let step = 0; step < maxSteps; step++) {
        let response = await client.messages.create({
          model,
          max_tokens,
          messages,
          tools: uniqueTools,
          ...anthropicOptions
        });
        if (response.stop_reason !== "tool_use") {
          let textContent = response.content.find(
            (block) => block.type === "text"
          );
          return {
            text: (textContent == null ? void 0 : textContent.text) || "",
            steps: step + 1
          };
        }
        let toolUseBlocks = response.content.filter(
          (block) => block.type === "tool_use"
        );
        let toolResponse = await session.callTools(toolUseBlocks);
        let toolResponseMessage = {
          role: "user",
          content: toolResponse.content.map((block) => ({
            type: "tool_result",
            tool_use_id: block.tool_use_id,
            content: block.content
          }))
        };
        messages.push(
          { role: "assistant", content: response.content },
          toolResponseMessage
        );
      }
      throw new Error(`Max steps (${maxSteps}) reached without final response`);
    }
  );
};
var runWithDeepSeek = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    ...deepseekOptions
  } = config;
  return withProviderSession(
    deepseek.metorialDeepseek,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      let tools = requestedTools ? session.tools.filter((t) => {
        var _a;
        return requestedTools.includes(((_a = t.function) == null ? void 0 : _a.name) || t.name);
      }) : session.tools;
      let uniqueTools = Array.from(
        new Map(tools.map((t) => {
          var _a;
          return [((_a = t.function) == null ? void 0 : _a.name) || t.name, t];
        })).values()
      );
      let messages = [
        { role: "user", content: message }
      ];
      for (let step = 0; step < maxSteps; step++) {
        let response = await client.chat.completions.create({
          model,
          messages,
          tools: uniqueTools,
          ...deepseekOptions
        });
        let choice = response.choices[0];
        if (!choice.message.tool_calls || choice.message.tool_calls.length === 0) {
          return {
            text: choice.message.content || "",
            steps: step + 1
          };
        }
        let toolResponses = await session.callTools(choice.message.tool_calls);
        messages.push(
          { role: "assistant", tool_calls: choice.message.tool_calls },
          ...toolResponses
        );
      }
      throw new Error(`Max steps (${maxSteps}) reached without final response`);
    }
  );
};
var runWithGoogle = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    ...googleOptions
  } = config;
  return withProviderSession(
    google.metorialGoogle,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      var _a, _b, _c, _d, _e, _f, _g, _h, _i;
      let tools = requestedTools ? session.tools.filter((t) => requestedTools.includes(t.name)) : session.tools;
      let response = await client.models.generateContent({
        model,
        contents: [
          {
            role: "user",
            parts: [{ text: message }]
          }
        ],
        config: {
          tools,
          ...googleOptions
        }
      });
      let text = (_e = (_d = (_c = (_b = (_a = response.candidates) == null ? void 0 : _a[0]) == null ? void 0 : _b.content) == null ? void 0 : _c.parts) == null ? void 0 : _d[0]) == null ? void 0 : _e.text;
      let functionCalls = (_i = (_h = (_g = (_f = response.candidates) == null ? void 0 : _f[0]) == null ? void 0 : _g.content) == null ? void 0 : _h.parts) == null ? void 0 : _i.filter((part) => part.functionCall).map((part) => part.functionCall);
      if (functionCalls && functionCalls.length > 0) {
        let toolResponses = await session.callTools(functionCalls);
        return {
          text: text || "",
          toolResponses,
          steps: 1
        };
      }
      return {
        text: text || "",
        steps: 1
      };
    }
  );
};
var extractTextFromContent = (content) => {
  if (typeof content === "string") {
    return content;
  }
  if (Array.isArray(content)) {
    return content.filter((chunk) => chunk && typeof chunk === "object").map((chunk) => chunk.text || chunk.content || JSON.stringify(chunk)).join("");
  }
  return "";
};
var runWithMistral = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    ...mistralOptions
  } = config;
  return withProviderSession(
    mistral.metorialMistral,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      let tools = requestedTools ? session.tools.filter((t) => {
        var _a;
        return requestedTools.includes(((_a = t.function) == null ? void 0 : _a.name) || t.name);
      }) : session.tools;
      let fixedTools = tools.map((tool) => {
        var _a;
        if ((_a = tool.function) == null ? void 0 : _a.parameters) {
          let fixedParams = { ...tool.function.parameters };
          fixedParams.additionalProperties = false;
          if (fixedParams.properties) {
            Object.values(fixedParams.properties).forEach((prop) => {
              if (prop && typeof prop === "object" && prop.type === "object") {
                prop.additionalProperties = false;
              }
            });
          }
          return {
            ...tool,
            function: {
              ...tool.function,
              parameters: fixedParams
            }
          };
        }
        return tool;
      });
      let messages = [
        { role: "user", content: message }
      ];
      for (let step = 0; step < maxSteps; step++) {
        let response = await client.chat.complete({
          model,
          messages,
          tools: fixedTools,
          ...mistralOptions
        });
        let choice = response.choices[0];
        let toolCalls = choice.message.toolCalls;
        if (!toolCalls || toolCalls.length === 0) {
          return {
            text: extractTextFromContent(choice.message.content),
            steps: step + 1
          };
        }
        let toolResponses = await session.callTools(toolCalls);
        messages.push(
          { role: "assistant", toolCalls },
          ...toolResponses
        );
      }
      throw new Error(`Max steps (${maxSteps}) reached without final response`);
    }
  );
};
var runWithXAI = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    ...xaiOptions
  } = config;
  return withProviderSession(
    xai.metorialXai,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      let tools = requestedTools ? session.tools.filter((t) => {
        var _a;
        return requestedTools.includes(((_a = t.function) == null ? void 0 : _a.name) || t.name);
      }) : session.tools;
      let uniqueTools = Array.from(
        new Map(tools.map((t) => [t.function.name, t])).values()
      );
      let messages = [
        { role: "user", content: message }
      ];
      for (let step = 0; step < maxSteps; step++) {
        let response = await client.chat.completions.create({
          model,
          messages,
          tools: uniqueTools,
          ...xaiOptions
        });
        let choice = response.choices[0];
        if (!choice.message.tool_calls || choice.message.tool_calls.length === 0) {
          return {
            text: choice.message.content || "",
            steps: step + 1
          };
        }
        let toolResponses = await session.callTools(choice.message.tool_calls);
        messages.push(
          { role: "assistant", tool_calls: choice.message.tool_calls },
          ...toolResponses
        );
      }
      throw new Error(`Max steps (${maxSteps}) reached without final response`);
    }
  );
};
var runWithTogetherAI = async (config) => {
  let {
    message,
    serverDeployments,
    client,
    model,
    maxSteps = 25,
    tools: requestedTools,
    withProviderSession,
    ...togetheraiOptions
  } = config;
  return withProviderSession(
    togetherai.metorialTogetherAi,
    {
      serverDeployments: Array.isArray(serverDeployments) ? serverDeployments : [serverDeployments]
    },
    async (session) => {
      let tools = requestedTools ? session.tools.filter((t) => {
        var _a;
        return requestedTools.includes(((_a = t.function) == null ? void 0 : _a.name) || t.name);
      }) : session.tools;
      let messages = [
        { role: "user", content: message }
      ];
      for (let step = 0; step < maxSteps; step++) {
        let response = await client.chat.completions.create({
          model,
          messages,
          tools,
          ...togetheraiOptions
        });
        let choice = response.choices[0];
        if (!choice.message.tool_calls || choice.message.tool_calls.length === 0) {
          return {
            text: choice.message.content || "",
            steps: step + 1
          };
        }
        let toolResponses = await session.callTools(choice.message.tool_calls);
        messages.push(
          { role: "assistant", tool_calls: choice.message.tool_calls },
          ...toolResponses
        );
      }
      throw new Error(`Max steps (${maxSteps}) reached without final response`);
    }
  );
};

// src/metorial.ts
var Metorial = class {
  constructor(init) {
    this.sdk = core.createMetorialCoreSDK(init);
  }
  get instance() {
    return this.sdk.instance;
  }
  get secrets() {
    return this.sdk.secrets;
  }
  get servers() {
    return this.sdk.servers;
  }
  get sessions() {
    return this.sdk.sessions;
  }
  get oauth() {
    return {
      ...this.sdk.oauth,
      waitForCompletion: this.waitForOAuthCompletion.bind(this)
    };
  }
  get _config() {
    return this.sdk._config;
  }
  get mcp() {
    return {
      createSession: (init) => new mcpSession.MetorialMcpSession(this.sdk, init),
      withSession: this.withSession.bind(this),
      withProviderSession: this.withProviderSession.bind(this),
      createConnection: this.createMcpConnection.bind(this)
    };
  }
  async createMcpConnection(init) {
    let session = new mcpSession.MetorialMcpSession(this.sdk, {
      serverDeployments: [init]
    });
    let deployments = await session.getServerDeployments();
    return await session.getClient({
      deploymentId: deployments[0].id
    });
  }
  async withSession(init, action) {
    let session = new mcpSession.MetorialMcpSession(this.sdk, init);
    try {
      return await action(session);
    } finally {
      await session.close();
    }
  }
  async withProviderSession(provider, init, action) {
    if (init.streaming) {
      return this.withStreamingSession(provider, init, action);
    }
    return this.withSession(init, async (session) => {
      let providerData = await provider(session);
      return action({
        ...providerData,
        session,
        getSession: session.getSession.bind(session),
        getCapabilities: session.getCapabilities.bind(session),
        getClient: session.getClient.bind(session),
        getServerDeployments: session.getServerDeployments.bind(session),
        getToolManager: session.getToolManager.bind(session)
      });
    });
  }
  async withStreamingSession(provider, init, action) {
    let session = new mcpSession.MetorialMcpSession(this.sdk, init);
    let sessionClosed = false;
    const closeSession = async () => {
      if (!sessionClosed) {
        sessionClosed = true;
        console.log("[Metorial] Closing streaming session");
        await session.close();
      }
    };
    try {
      let providerData = await provider(session);
      let result = await action({
        ...providerData,
        session,
        getSession: session.getSession.bind(session),
        getCapabilities: session.getCapabilities.bind(session),
        getClient: session.getClient.bind(session),
        getServerDeployments: session.getServerDeployments.bind(session),
        getToolManager: session.getToolManager.bind(session),
        closeSession
      });
      setTimeout(async () => {
        if (!sessionClosed) {
          console.log("[Metorial] Streaming timeout reached - auto-closing session");
          await closeSession();
        }
      }, 6e4);
      return result;
    } catch (error) {
      await closeSession();
      throw error;
    }
  }
  inferProvider(model) {
    let modelLower = model.toLowerCase();
    if (modelLower.startsWith("claude-")) {
      return "anthropic";
    }
    if (modelLower.startsWith("gpt-") || modelLower.startsWith("o1-")) {
      return "openai";
    }
    if (modelLower.includes("deepseek")) {
      return "deepseek";
    }
    if (modelLower.startsWith("gemini-") || modelLower.includes("google")) {
      return "google";
    }
    if (modelLower.startsWith("mistral-") || modelLower.includes("mistral")) {
      return "mistral";
    }
    if (modelLower.startsWith("x-") || modelLower === "grok-beta") {
      return "xai";
    }
    if (modelLower.includes("together") || modelLower.includes("llama") || modelLower.includes("mixtral") || modelLower.includes("qwen") || modelLower.includes("/")) {
      return "togetherai";
    }
    throw new Error(`Unable to infer provider from model "${model}".`);
  }
  async waitForOAuthCompletion(sessions, options) {
    var _a, _b;
    let pollInterval = Math.max((_a = options == null ? void 0 : options.pollInterval) != null ? _a : 5e3, 2e3);
    let timeout = (_b = options == null ? void 0 : options.timeout) != null ? _b : 6e5;
    let startTime = Date.now();
    if (sessions.length === 0) {
      return;
    }
    while (true) {
      if (Date.now() - startTime > timeout) {
        throw new Error(`OAuth authentication timeout after ${timeout / 1e3} seconds`);
      }
      try {
        let statuses = await Promise.all(
          sessions.map((session) => this.oauth.sessions.get(session.id))
        );
        let allCompleted = statuses.every((status) => status.status === "completed");
        if (allCompleted) {
          return;
        }
        let failedSessions = statuses.filter((status) => status.status === "failed");
        if (failedSessions.length > 0) {
          throw new Error(
            `OAuth authentication failed for ${failedSessions.length} session(s)`
          );
        }
        await new Promise((resolve) => setTimeout(resolve, pollInterval));
      } catch (error) {
        if (error instanceof Error && (error.message.includes("OAuth authentication failed") || error.message.includes("OAuth authentication timeout"))) {
          throw error;
        }
        await new Promise((resolve) => setTimeout(resolve, pollInterval));
      }
    }
  }
  async run(config) {
    let provider = this.inferProvider(config.model);
    switch (provider) {
      case "openai":
        return runWithOpenAI({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      case "anthropic":
        return runWithAnthropic({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      case "deepseek":
        return runWithDeepSeek({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      case "google":
        return runWithGoogle({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      case "mistral":
        return runWithMistral({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      case "xai":
        return runWithXAI({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      case "togetherai":
        return runWithTogetherAI({
          ...config,
          client: config.client,
          withProviderSession: this.withProviderSession.bind(this)
        });
      default:
        throw new Error(`Unsupported provider: ${provider}`);
    }
  }
};

exports.Metorial = Metorial;
//# sourceMappingURL=index.cjs.map
//# sourceMappingURL=index.cjs.map